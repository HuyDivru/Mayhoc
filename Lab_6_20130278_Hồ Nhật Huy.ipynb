{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ALexTommy1223/Mayhoc/blob/main/Lab_6_20130278_H%E1%BB%93%20Nh%E1%BA%ADt%20Huy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab is to deal with classification task using **Random Forests** and **Na√Øve Bayes** algorithms with/without **Feature Selection**. \n",
        "\n",
        "*   **Deadline: 23:59, 25/03/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/MyDrive/ML'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYF5XXcUoEpV",
        "outputId": "ad0af3de-e93a-4372-ecd3-996c3a68bec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/ML\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. \n",
        "Task 1. Compare the performance of selected classification algorithms including **Random forest**, **NaiveBayes**, and **SVM** with **mnist** dataset based on **accuracy, precision, recall, f1** measures according to **without using selection feature** and **using selection feature**.\n",
        "\n"
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the mnist dataset and split into training and testing sets\n",
        "digits = load_digits()\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train and evaluate the Random Forest classifier without selection feature\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "print(\"Random Forest without Feature Selection\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
        "print(\"F1 score:\", f1_score(y_test, y_pred, average='macro'))\n",
        "\n",
        "# Train and evaluate the Naive Bayes classifier without selection feature\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred = nb.predict(X_test)\n",
        "print(\"Naive Bayes without Feature Selection\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
        "print(\"F1 score:\", f1_score(y_test, y_pred, average='macro'))\n",
        "\n",
        "# Train and evaluate the SVM classifier without  selection feature\n",
        "svc = SVC(random_state=42)\n",
        "svc.fit(X_train, y_train)\n",
        "y_pred = svc.predict(X_test)\n",
        "print(\"SVM without Feature Selection\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
        "print(\"F1 score:\", f1_score(y_test, y_pred, average='macro'))\n",
        "\n",
        "# Apply selection  feature \n",
        "selector = SelectKBest(chi2, k=20)\n",
        "X_train_new = selector.fit_transform(X_train, y_train)\n",
        "X_test_new = selector.transform(X_test)\n",
        "\n",
        "# Train and evaluate the Random Forest classifier with  selection feature\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train_new, y_train)\n",
        "y_pred = rf.predict(X_test_new)\n",
        "print(\"Random Forest with Feature Selection\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
        "print(\"F1 score:\", f1_score(y_test, y_pred, average='macro'))\n",
        "\n",
        "# Train and evaluate the Naive Bayes classifier with selection feature\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train_new, y_train)\n",
        "y_pred = nb.predict(X_test_new)\n",
        "print(\"Naive Bayes with Feature Selection\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
        "print(\"F1 score:\", f1_score(y_test, y_pred, average='macro'))\n",
        "\n",
        "# Train and evaluate the SVM classifier with selection feature\n",
        "svc = SVC(random_state=42)\n",
        "svc.fit(X_train_new, y_train)\n",
        "y_pred = svc.predict(X_test_new)\n",
        "print(\"SVM with Feature Selection\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
        "print(\"F1 score:\", f1_score(y_test, y_pred, average='macro'))"
      ],
      "metadata": {
        "id": "sOsg77IBzEyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e564c08-9729-4fd8-dcf9-39d4694b2953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest without Feature Selection\n",
            "Accuracy: 0.975925925925926\n",
            "Precision: 0.9761599112487012\n",
            "Recall: 0.9764231664735898\n",
            "F1 score: 0.9761973169254977\n",
            "Naive Bayes without Feature Selection\n",
            "Accuracy: 0.8518518518518519\n",
            "Precision: 0.8668799024332581\n",
            "Recall: 0.8492283225937289\n",
            "F1 score: 0.8475555476524305\n",
            "SVM without Feature Selection\n",
            "Accuracy: 0.987037037037037\n",
            "Precision: 0.9864843840705909\n",
            "Recall: 0.987404487656754\n",
            "F1 score: 0.9869102479765148\n",
            "Random Forest with Feature Selection\n",
            "Accuracy: 0.9537037037037037\n",
            "Precision: 0.952743485191235\n",
            "Recall: 0.9531925529853826\n",
            "F1 score: 0.9523394222665356\n",
            "Naive Bayes with Feature Selection\n",
            "Accuracy: 0.7648148148148148\n",
            "Precision: 0.807850247148244\n",
            "Recall: 0.7657237592467466\n",
            "F1 score: 0.7614977718632439\n",
            "SVM with Feature Selection\n",
            "Accuracy: 0.9555555555555556\n",
            "Precision: 0.9540820067980901\n",
            "Recall: 0.9537612714206969\n",
            "F1 score: 0.9534001695255002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. \n",
        "For given bank dataset (bank.csv) having the following attributes :\n",
        "1.\t**age** (numeric)\n",
        "2.\t**job** : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
        "3.\t**marital** : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
        "4.\t**education** (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
        "5.\t**default**: has credit in default? (categorical: 'no','yes','unknown')\n",
        "6.\t**housing**: has housing loan? (categorical: 'no','yes','unknown')\n",
        "7.\t**loan**: has personal loan? (categorical: 'no','yes','unknown')\n",
        "8.\t**contact**: contact communication type (categorical: 'cellular','telephone')\n",
        "9.\t**month**: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
        "10.\t**day_of_week**: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
        "11.\t**duration**: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
        "12.\t**campaign**: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
        "13.\t**pdays**: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
        "14.\t**previous**: number of contacts performed before this campaign and for this client (numeric)\n",
        "15.\t**poutcome**: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
        "Output variable (desired target):\n",
        "16.\t**y**. has the client subscribed a term deposit? (binary: 'yes','no')\n",
        "\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.1. Apply StandardScaler() function to columns that contains numerical data ('age', 'balance', 'day', 'campaign', 'pdays', 'previous')"
      ],
      "metadata": {
        "id": "q89LEvT7dqaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "df = pd.read_csv('bank.csv')\n",
        "num_cols = ['age', 'balance', 'day', 'campaign', 'pdays', 'previous']\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "8vx3mfIidu4P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70980e7e-973e-4343-f0b0-967c26d235cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        age         job  marital  education default   balance housing loan  \\\n",
            "0  1.491505      admin.  married  secondary      no  0.252525     yes   no   \n",
            "1  1.239676      admin.  married  secondary      no -0.459974      no   no   \n",
            "2 -0.019470  technician  married  secondary      no -0.080160     yes   no   \n",
            "3  1.155733    services  married  secondary      no  0.293762     yes   no   \n",
            "4  1.071790      admin.  married   tertiary      no -0.416876      no   no   \n",
            "\n",
            "   contact       day month  duration  campaign     pdays  previous poutcome  \\\n",
            "0  unknown -1.265746   may      1042 -0.554168 -0.481184  -0.36326  unknown   \n",
            "1  unknown -1.265746   may      1467 -0.554168 -0.481184  -0.36326  unknown   \n",
            "2  unknown -1.265746   may      1389 -0.554168 -0.481184  -0.36326  unknown   \n",
            "3  unknown -1.265746   may       579 -0.554168 -0.481184  -0.36326  unknown   \n",
            "4  unknown -1.265746   may       673 -0.186785 -0.481184  -0.36326  unknown   \n",
            "\n",
            "  deposit  \n",
            "0     yes  \n",
            "1     yes  \n",
            "2     yes  \n",
            "3     yes  \n",
            "4     yes  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.2. Apply Encode Categorical Value (OneHotEncoder) to transfrom categorical data to numerical data ('job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome')"
      ],
      "metadata": {
        "id": "r7acR0TxdvY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import th∆∞ vi·ªán\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV\n",
        "df = pd.read_csv('bank.csv')\n",
        "cat_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "encoded_cols = pd.DataFrame(encoder.fit_transform(df[cat_cols]).toarray())\n",
        "cat_values = encoder.categories_\n",
        "feature_names = []\n",
        "for i, col in enumerate(cat_cols):\n",
        "    for value in cat_values[i]:\n",
        "        feature_names.append(col + '_' + value)\n",
        "encoded_cols.columns = feature_names\n",
        "\n",
        "df_encoded = pd.concat([df, encoded_cols], axis=1)\n",
        "df_encoded.drop(columns=cat_cols, inplace=True)\n",
        "print(df_encoded.head())\n",
        "print(df_encoded.head())"
      ],
      "metadata": {
        "id": "egtgBmAtd0um",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5220c9e7-8baf-459c-b7b7-650ecce30cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age  balance  day  duration  campaign  pdays  previous deposit  job_admin.  \\\n",
            "0   59     2343    5      1042         1     -1         0     yes         1.0   \n",
            "1   56       45    5      1467         1     -1         0     yes         1.0   \n",
            "2   41     1270    5      1389         1     -1         0     yes         0.0   \n",
            "3   55     2476    5       579         1     -1         0     yes         0.0   \n",
            "4   54      184    5       673         2     -1         0     yes         1.0   \n",
            "\n",
            "   job_blue-collar  ...  month_jun  month_mar  month_may  month_nov  \\\n",
            "0              0.0  ...        0.0        0.0        1.0        0.0   \n",
            "1              0.0  ...        0.0        0.0        1.0        0.0   \n",
            "2              0.0  ...        0.0        0.0        1.0        0.0   \n",
            "3              0.0  ...        0.0        0.0        1.0        0.0   \n",
            "4              0.0  ...        0.0        0.0        1.0        0.0   \n",
            "\n",
            "   month_oct  month_sep  poutcome_failure  poutcome_other  poutcome_success  \\\n",
            "0        0.0        0.0               0.0             0.0               0.0   \n",
            "1        0.0        0.0               0.0             0.0               0.0   \n",
            "2        0.0        0.0               0.0             0.0               0.0   \n",
            "3        0.0        0.0               0.0             0.0               0.0   \n",
            "4        0.0        0.0               0.0             0.0               0.0   \n",
            "\n",
            "   poutcome_unknown  \n",
            "0               1.0  \n",
            "1               1.0  \n",
            "2               1.0  \n",
            "3               1.0  \n",
            "4               1.0  \n",
            "\n",
            "[5 rows x 52 columns]\n",
            "   age  balance  day  duration  campaign  pdays  previous deposit  job_admin.  \\\n",
            "0   59     2343    5      1042         1     -1         0     yes         1.0   \n",
            "1   56       45    5      1467         1     -1         0     yes         1.0   \n",
            "2   41     1270    5      1389         1     -1         0     yes         0.0   \n",
            "3   55     2476    5       579         1     -1         0     yes         0.0   \n",
            "4   54      184    5       673         2     -1         0     yes         1.0   \n",
            "\n",
            "   job_blue-collar  ...  month_jun  month_mar  month_may  month_nov  \\\n",
            "0              0.0  ...        0.0        0.0        1.0        0.0   \n",
            "1              0.0  ...        0.0        0.0        1.0        0.0   \n",
            "2              0.0  ...        0.0        0.0        1.0        0.0   \n",
            "3              0.0  ...        0.0        0.0        1.0        0.0   \n",
            "4              0.0  ...        0.0        0.0        1.0        0.0   \n",
            "\n",
            "   month_oct  month_sep  poutcome_failure  poutcome_other  poutcome_success  \\\n",
            "0        0.0        0.0               0.0             0.0               0.0   \n",
            "1        0.0        0.0               0.0             0.0               0.0   \n",
            "2        0.0        0.0               0.0             0.0               0.0   \n",
            "3        0.0        0.0               0.0             0.0               0.0   \n",
            "4        0.0        0.0               0.0             0.0               0.0   \n",
            "\n",
            "   poutcome_unknown  \n",
            "0               1.0  \n",
            "1               1.0  \n",
            "2               1.0  \n",
            "3               1.0  \n",
            "4               1.0  \n",
            "\n",
            "[5 rows x 52 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.3. Apply **Decision tree, Random forest, kNN, Na√ØveBayes** to preproceed dataset in the previous steps. Then compare the obtained results using **accuracy, precision, recall, f1** measures."
      ],
      "metadata": {
        "id": "K2Si6d69d1nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† t·∫≠p ki·ªÉm tra\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_encoded.drop('target', axis=1), df_encoded['target'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Kh·ªüi t·∫°o c√°c m√¥ h√¨nh\n",
        "models = {\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'kNN': KNeighborsClassifier(),\n",
        "    'Naive Bayes': GaussianNB()\n",
        "}\n",
        "\n",
        "# Kh·ªüi t·∫°o c√°c m√¥ h√¨nh\n",
        "models = {\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'kNN': KNeighborsClassifier(),\n",
        "    'Naive Bayes': GaussianNB()\n",
        "}\n",
        "\n",
        "# Hu·∫•n luy·ªán v√† ƒë√°nh gi√° c√°c m√¥ h√¨nh\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred)\n",
        "    rec = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    print(\"Model: \", name)\n",
        "    print(\"Accuracy: \", round(acc, 4))\n",
        "    print(\"Precision: \", round(prec, 4))\n",
        "    print(\"Recall: \", round(rec, 4))\n",
        "    print(\"F1-Score: \", round(f1, 4))"
      ],
      "metadata": {
        "id": "Ouil-cf_d8jW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "d634d6c6-ff02-4942-ef5a-6aa9fbe712a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-a103cb40f417>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† t·∫≠p ki·ªÉm tra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_encoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Kh·ªüi t·∫°o c√°c m√¥ h√¨nh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4955\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4956\u001b[0m         \"\"\"\n\u001b[0;32m-> 4957\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4958\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4959\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4265\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4266\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4267\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   4309\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4310\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4311\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4312\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6659\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6660\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6661\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{list(labels[mask])} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6662\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6663\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['target'] not found in axis\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.4. Using selection feature to above dataset, then compare the classification results with those in Task 2.3. "
      ],
      "metadata": {
        "id": "SweVRB4meApP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "seFBhqCSeC7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4. \n",
        "For a given dataset in the Lab #5 (**credit card dataset**), perform feature selection and thencompare the performance of selected classification algorithms (Decision Tree, kNN, Logistic Regression, SVM, Random Forest and NaiveBayes) based on accuracy, precision, recall, f1 measures.\n"
      ],
      "metadata": {
        "id": "Z5pp7_h-aP2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code"
      ],
      "metadata": {
        "id": "Rw_-8FIf2KxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}